import __3dSpec
import audio2img
import config
import __createSpectrogram
import fileLoad
import load
import makeSpec
import models
import sysModConfig
import _visual_config


# -*- coding: utf-8 -*-
"""HeartSound_Test3.2_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WMD1YWZ1SfId_zG5A3iGpXqtkRANrRzd
"""
import zipfile
import os
trainZip = 'training.zip'
validationZip = 'validation.zip'

trainLoc = 'train'
valLoc = 'val'
if not os.path.exists(trainLoc):
  os.mkdir(trainLoc)

if not os.path.exists(valLoc):
  os.mkdir(valLoc)


  
with zipfile.ZipFile(trainZip, 'r') as zip_ref:
    zip_ref.extractall(trainLoc)

with zipfile.ZipFile(validationZip, 'r') as zip_ref:
    zip_ref.extractall(valLoc)

training_a = os.listdir('train/training-a')
print(len(training_a))
print(training_a[1])

! rm -rf *.zip

import scipy.io.wavfile
import numpy as np
import IPython.display as ipd
import matplotlib.pyplot as plt

test_file = 'train/training-c/c0028.wav'
sample_rate, sig = scipy.io.wavfile.read(test_file)
print('sampling rate: ', sample_rate)
print('length of samples', len(sig))

t = np.linspace(0, len(sig)/sample_rate, len(sig))
fig = plt.figure(figsize=(25,10))
ax1 = fig.add_subplot(211)
ax1.set_xlabel("time (sec)")
ax1.set_ylabel("amplitude")
ax1.set_title("Time domain signal plot")
ax1.plot(t, sig)

pre_emphasis = 0.97
emphasized_signal = np.append(sig[0], sig[1:] - pre_emphasis * sig[:-1])

t = np.linspace(0, len(emphasized_signal)/sample_rate, len(sig))
fig = plt.figure(figsize=(25,10))
ax1 = fig.add_subplot(211)
ax1.set_xlabel("time (sec)")
ax1.set_ylabel("amplitude")
ax1.set_title("Time domain signal plot")
ax1.plot(t, emphasized_signal)

ipd.Audio(emphasized_signal, rate=sample_rate)

files = os.listdir('/content/train/training-a')
files[10][-3:]

import sys
def find_min_max_file_length(folder_location):
  subfolders = os.listdir(folder_location)
  lengths = []
  sample_rates = []
  fileIndex = 0
  totalFiles = 0
  for subfolder in subfolders:
    tempFiles = os.listdir(folder_location+'/'+subfolder)
    files = [file for file in tempFiles if file[-3:] == 'wav']
    totalFiles = totalFiles+len(files)
  
  
  for subfolder in subfolders:
    files = os.listdir(folder_location+'/'+subfolder)
    print(subfolder)
    
    for file in files:
      if file[-3:] == 'wav':
        opened_file = folder_location+ '/' +subfolder + '/' + file
        sample_rate, signal = scipy.io.wavfile.read(opened_file)
        sample_rates.append(sample_rate)
        if len(signal) == 243997:
          x = folder_location+'/'+subfolder+'/'+file
        lengths.append(len(signal))
        fileIndex = fileIndex+1
        if (fileIndex%100 == 0):
          print(subfolder + '/'+file+':' + str(fileIndex / totalFiles*100) + '% extraction done')
        sys.stdout.flush()

    print(subfolder + ": "+ "extraction completed")
  print(len(lengths))
  print(len(sample_rates))
  print(x)
  return (min(lengths), max(lengths))

(min_signal_length, max_signal_length) = find_min_max_file_length(folder_location=trainLoc)
print((min_signal_length, max_signal_length))

import pandas as pd
val_csv = '/content/val/validation/REFERENCE.csv'
val_info = pd.read_csv(val_csv, names = ['file', 'class'])
val_list = val_info['file'].values.tolist()
val_list = [val_list[i]+'.wav' for i in range(len(val_list))]
print(val_list)



import pandas as pd
def ModifiedLoading(folder_location, signal_length, val_list, pre_emphasis = False, pre_emphasis_ratio = 0.79, train_or_val = 'train'):
  subfolders = os.listdir(folder_location)
  lengths = []
  sample_rates = []
  fileIndex = 0
  totalFiles = 0

  for subfolder in subfolders:
    tempFiles = os.listdir(folder_location+'/'+subfolder)
    files = [file for file in tempFiles if file[-3:] == 'wav']
    totalFiles = totalFiles+len(files)


  print("total number of files: ", totalFiles)
  if train_or_val == 'train':
    x = np.zeros(shape = (totalFiles-len(val_list), min_signal_length))
    y = np.zeros(shape = (totalFiles-len(val_list), 1))
  elif train_or_val == 'val':
    x = np.zeros(shape = (totalFiles, min_signal_length))
    y = np.zeros(shape = (totalFiles, 1))

  
  for subfolder in subfolders:
    csv_file = folder_location + '/' + subfolder + '/REFERENCE.csv'
    csv_info = pd.read_csv(csv_file, names = ['file', 'class'])


    for i in range (0, len(csv_info)):
      if train_or_val == 'train':
        if csv_info['file'][i]+'.wav' not in val_list:
          fileName = folder_location + '/' + subfolder + '/' + csv_info['file'][i]+'.wav'
          print(csv_info['file'][i], csv_info['class'][i])
          y[fileIndex] = 0 if csv_info['class'][i] == 1 else 1
          sample_rate, sig = scipy.io.wavfile.read(fileName)
          if pre_emphasis == True:
            sig =  np.append(sig[0], sig[1:] - pre_emphasis_ratio * sig[:-1])
          x[fileIndex, 0:signal_length] = sig[0:signal_length]
          fileIndex = fileIndex + 1
      elif train_or_val == 'val':
        fileName = folder_location + '/' + subfolder + '/' + csv_info['file'][i]+'.wav'
        print(csv_info['file'][i], csv_info['class'][i])
        y[fileIndex] = 0 if csv_info['class'][i] == 1 else 1
        sample_rate, sig = scipy.io.wavfile.read(fileName)
        if pre_emphasis == True:
          sig =  np.append(sig[0], sig[1:] - pre_emphasis_ratio * sig[:-1])
        x[fileIndex, 0:signal_length] = sig[0:signal_length]
        fileIndex = fileIndex + 1

  print(train_or_val + ' set generation completed')
  return x, y



X_train, Y_train = ModifiedLoading(folder_location='/content/train', signal_length= min_signal_length,val_list = val_list, pre_emphasis = False, train_or_val = 'train')

X_train.shape

np.sum(Y_train)

Y_train.shape

np.unique(Y_train)

X_val, Y_val = ModifiedLoading(folder_location='/content/val', signal_length= min_signal_length, val_list = val_list, pre_emphasis = False, train_or_val = 'val')

np.sum(Y_val)

Y_val.shape

trainlength = Y_train.shape[0]
vallength = Y_val.shape[0]
print(trainlength)
print(vallength)

t = np.linspace(0, len(X_val[105])/sample_rate, len(X_val[105]))
fig = plt.figure(figsize=(25,10))
ax1 = fig.add_subplot(211)
ax1.set_xlabel("time (sec)")
ax1.set_ylabel("amplitude")
ax1.set_title("Time domain signal plot")
ax1.plot(t, X_val[105])

from scipy import signal
def spectrogram(sig_in):
    nperseg = 256 # default 256
    noverlap = nperseg // 4 # default: nperseg // 8
    fs = sample_rate# raw signal sample rate is 2000Hz
    window = 'triang'
    scaling = 'density' # {'density', 'spectrum'}
    detrend = 'linear' # {'linear', 'constant', False}
    eps = 1e-11
    f, t, Sxx = signal.spectrogram(sig_in, nperseg=nperseg, noverlap=noverlap,
                                   fs=fs, window=window,
                                   scaling=scaling, detrend=detrend)
    return f, t, np.log(Sxx + eps)

audio_index = 120
f, t, Sxx_out = spectrogram(X_train[audio_index, :])

fig = plt.figure(figsize=(18, 8))
ax = fig.add_subplot(2, 1, 1)
ax.margins(x=0.003)
plt.plot(X_train[audio_index, :])
plt.title('signal:', fontsize=18, loc='left')
plt.axis('off')

ax = fig.add_subplot(2, 1, 2)
cmap = plt.get_cmap('magma')
spec = plt.pcolormesh(t, f, Sxx_out, cmap=cmap)
plt.title('normalized log spectrogram (aspect stretched):',
          fontsize=18, loc='left')
plt.axis('off');

Sxx_out.shape

X_train.shape

Y_train.shape

from scipy.stats import multivariate_normal

X, Y = np.meshgrid(t,f)


fig = plt.figure(figsize=(40, 25))
ax = fig.add_subplot(111, projection='3d')
ax.plot_surface(Y, X, Sxx_out, cmap="plasma")

plt.show()

N_CHANNELS = 3
ctrogram dims: {sxx_h}x{sxx_w}')
print(f'base spectrogram mean, sigma: {moments[0]:.4f}, {moments[1]:.4f}')
print(f'delta spectrogram mean, sigma: {moments[2]:.4f}, {moments[3]:.4f}')
print(f'delta-delta spectrogram mean, sigma: {moments[4]:.4f}, {moments[5]:.4f}')

start = 0
sig_in = X_train[100, :]

f, t, Sxx = spectrogram(sig_in)
s3d = get_3d_spec(Sxx, moments)

fig = plt.figure(figsize=(27, 24))
ax = fig.add_subplot(4, 1, 1)
ax.margins(x=0.003)
plt.plot(X_train[0,:])
plt.title('signal:', fontsize=40, loc='left')
plt.axis('off')

ax = fig.add_subplot(4, 1, 2)
cmap = plt.get_cmap('magma')
spec = plt.pcolormesh(t, f, s3d[:, :, 0], cmap=cmap)
plt.title('log spectrogram ',
          fontsize=40, loc='left')
plt.axis('off')

ax = fig.add_subplot(4, 1, 3)
spec = plt.pcolormesh(t, f, s3d[:, :, 1], cmap=cmap)
plt.title('delta log spectrogram:', fontsize=40, loc='left')
plt.axis('off')

ax = fig.add_subplot(4, 1, 4)
spec = plt.pcolormesh(t, f, s3d[:, :, 2], cmap=cmap)
plt.title('delta-delta log spectrogram:', fontsize=40, loc='left')
plt.axis('off');

from scipy.stats import multivariate_normal
t, f = np.meshgrid(t,f)
fig = plt.figure(figsize=(25, 16))
ax = fig.add_subplot(111, projection='3d')
ax.plot_surface(f, t, s3d[:, :, 2], cmap="plasma")
ax.set_xlabel('Frequency (Hz)', fontsize = 20)
ax.set_ylabel('Time(sec)', fontsize = 20)
ax.set_zlabel('Magnitude', fontsize = 20)
plt.show()
'''
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.plot_surface(f, t, s3d[:, :, 1], cmap="plasma")
plt.show()
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.plot_surface(f, t, s3d[:, :, 2], cmap="plasma")
plt.show()
'''

plt.figure(figsize=(18, 4))
cmap = plt.get_cmap('magma')
ax = plt.pcolormesh(t, f/1000, s3d[:, :, 0], cmap=cmap)
plt.ylabel(r'frequency (kHz)', fontsize=14)
ax.axes.tick_params(axis='y', labelsize=14)
ax.axes.get_xaxis().set_visible(False);

from sklearn.utils import shuffle
X_train, Y_train = shuffle(X_train, Y_train)
X_val, Y_val = shuffle(X_val, Y_val)

def get_image_from_audio(data):
  _,_,sxx = spectrogram(data[0])
  sxx3d = get_3d_spec(sxx,moments)
  (height, width, channels) = sxx3d.shape


  processed_data = np.zeros(shape = (data.shape[0], height, width, channels)) 

  for i in range(0, data.shape[0]):
    _,_,sxx = spectrogram(data[i])
    processed_data[i] = get_3d_spec(sxx, moments)

  return processed_data

processed_X_train = get_image_from_audio(X_train)
processed_X_val = get_image_from_audio(X_val)

processed_X_train.shape

np.max(processed_X_train)

np.min(processed_X_train)

np.max(processed_X_val)

np.min(processed_X_val)

plt.imshow(processed_X_train[525])

import keras
from keras import Model, Input
#from keras.applications import ResNet50
from tensorflow.keras.optimizers import Adam
#from keras.utils import plot_model
from keras.callbacks import *
from keras.layers import *
import tensorflow as tf

def channelAttention(inLayer, n):
  att_1 = GlobalAveragePooling2D()(inLayer)
  att_1 = Dense(att_1.shape[1]*n, activation = 'relu')(att_1)
  att_1 = Dense(int(att_1.shape[1]/n), activation = 'sigmoid')(att_1)
  out = Multiply()([inLayer, tf.expand_dims(tf.expand_dims(att_1,axis=1), axis=1)])
  return out

def pixelAttention(inLayer, n):
  att_1 = Conv2DTranspose(filters = n*inLayer.shape[3], kernel_size = 3, strides = n, activation = 'relu')(inLayer)
  att_1 = BatchNormalization()(att_1)
  print(att_1.shape)
  att_1 = Conv2D(filters = inLayer.shape[3], kernel_size = 3, strides = n, activation = 'sigmoid')(att_1)
  att_1 = BatchNormalization()(att_1)
  print(att_1.shape)
  print(inLayer.shape)
  out = Multiply()([inLayer, att_1])
  return out

def network (height = processed_X_train.shape[1], width = processed_X_train.shape[2], channels = processed_X_train.shape[3]):
  inputs = Input((height, width, channels))
  mid_1 = Conv2D(filters = 32, kernel_size = 3, strides= 1, padding = 'valid')(inputs)
  out1 = pixelAttention(mid_1, 2)
  out1 = BatchNormalization()(out1)
  print(out1.shape)
  out1 = Conv2D(filters = 64, kernel_size = 3, strides= 1, padding = 'valid')(out1)
  out1 = BatchNormalization()(out1)
  out1 = GlobalAveragePooling2D()(out1)
  out1 = Dense(64, activation = 'softmax')(out1)

  conv1 = Conv1D(filters = 4, kernel_size= 3, strides= 2, padding='valid', activation='relu')(inputs)
  conv1 = BatchNormalization()(conv1)
  print(conv1.shape)
  conv2 = Conv1D(filters = 8, kernel_size= 3, strides= 2, padding='valid', activation='relu')(conv1)
  conv2 = BatchNormalization()(conv2)
  print(conv2.shape)
  conv3 = Conv1D(filters = 16, kernel_size= 3, strides= 2, padding='valid', activation= 'relu')(conv2)
  conv3 = BatchNormalization()(conv3)
  print(conv3.shape)
  conv4 = Conv1D(filters = 32, kernel_size= 3, strides= 2, padding='valid', activation = 'relu')(conv3)
  conv4 = BatchNormalization()(conv4)
  print(conv4.shape)
  
  '''
  reshaped = Reshape((493, 32, 1))(conv4)
  print(reshaped.shape)

  conv5 = Conv2D(filters = 64, kernel_size=3, strides = 2, padding='valid', activation = 'relu')(reshaped)
  print(conv5.shape)

  conv6 = Conv2D(filters = 128, kernel_size=3, strides = 2, padding='valid', activation = 'relu')(conv5)
  print(conv6.shape)

  '''
  flat = Flatten()(conv4)
  print(flat.shape)

  den1 = Dense(64, activation = 'softmax')(flat)
  print(den1.shape)
  mul = Concatenate()([den1, out1])
  mul = BatchNormalization()(mul)
  out = Dense(1, activation = 'sigmoid')(mul)
  model = Model(inputs = inputs, outputs = out)

  return model

def architecture_1(height = processed_X_train.shape[1], width = processed_X_train.shape[2], channels = processed_X_train.shape[3]):
  inputs = Input((height, width, channels))
  conv1 = Conv1D(filters = 4, kernel_size= 3, strides= 2, padding='valid', activation='relu')(inputs)
  conv1 = BatchNormalization()(conv1)
  print(conv1.shape)
  conv2 = Conv1D(filters = 8, kernel_size= 3, strides= 2, padding='valid', activation='relu')(conv1)
  conv2 = BatchNormalization()(conv2)
  print(conv2.shape)
  conv3 = Conv1D(filters = 16, kernel_size= 3, strides= 2, padding='valid', activation= 'relu')(conv2)
  conv3 = BatchNormalization()(conv3)
  print(conv3.shape)
  conv4 = Conv1D(filters = 32, kernel_size= 3, strides= 2, padding='valid', activation = 'relu')(conv3)
  conv4 = BatchNormalization()(conv4)
  print(conv4.shape)

  flat = Flatten()(conv4)
  print(flat.shape)

  den1 = Dense(6, activation = 'softmax')(flat)
  model = Model(inputs = inputs, outputs = den1)

  return model

def architecture_2(height = processed_X_train.shape[1], width = processed_X_train.shape[2], channels = processed_X_train.shape[3]):
  inputs = Input((height, width, channels))
  mid_1 = Conv2D(filters = 32, kernel_size = 3, strides= 1, padding = 'valid')(inputs)
  out1 = BatchNormalization()(mid_1)
  print(out1.shape)
  out1 = Conv2D(filters = 64, kernel_size = 3, strides= 1, padding = 'valid')(out1)
  out1 = BatchNormalization()(out1)
  out1 = GlobalAveragePooling2D()(out1)
  out1 = Dense(6, activation = 'softmax')(out1)
  model = Model(inputs = inputs, outputs = out1)

  return model

def architecture_3(height = processed_X_train.shape[1], width = processed_X_train.shape[2], channels = processed_X_train.shape[3]):
  inputs = Input((height, width, channels))
  mid_1 = Conv2D(filters = 32, kernel_size = 3, strides= 1, padding = 'valid')(inputs)
  out1 = pixelAttention(mid_1, 2)
  out1 = BatchNormalization()(out1)
  print(out1.shape)
  out1 = Conv2D(filters = 64, kernel_size = 3, strides= 1, padding = 'valid')(out1)
  out1 = BatchNormalization()(out1)
  out1 = GlobalAveragePooling2D()(out1)
  out1 = Dense(6, activation = 'softmax')(out1)

  model = Model(inputs = inputs, outputs = out1)

  return model

model = network()

model.summary()

model.compile(loss='binary_crossentropy',
                      optimizer= Adam(lr=0.0008),
                      metrics=['accuracy'])
#plot_model(model)

from keras.callbacks import *
weight_saver = ModelCheckpoint('/content/drive/MyDrive/HeartSound/test3.1_1_1.h5', monitor='val_accuracy', 
                                save_best_only=True, save_weights_only=False, mode= 'max')

annealer = ReduceLROnPlateau(monitor='val_loss', factor=0.5,
                              patience=5, min_lr=0.0001,mode= 'min')

hist = model.fit(x = processed_X_train , 
                          y = Y_train, 
                          batch_size = 8,
                          epochs = 6000,
                          callbacks = [weight_saver , annealer],
                          #validation_data = (processed_X_val, Y_val),
                          validation_split = 0.2,
                          shuffle = True,
                          verbose = 1)



# summarize history for accuracy
fig = plt.figure(figsize=(60, 20))
ax = fig.add_subplot(1, 2, 1)
ax.margins(x=0.003)
plt.plot(hist.history['accuracy'],linewidth=5)
plt.plot(hist.history['val_accuracy'],linewidth=5)
plt.title('model accuracy', fontsize = 35)
plt.ylabel('accuracy', fontsize = 25)
plt.xlabel('epoch' , fontsize = 25)
plt.legend(['train', 'validation'], loc='upper left', fontsize = 25)
#plt.show()
# summarize history for loss
ax = fig.add_subplot(1, 2, 2)
plt.plot(hist.history['loss'],linewidth=5)
plt.plot(hist.history['val_loss'],linewidth=5)
plt.title('model loss', fontsize = 35)
plt.ylabel('loss', fontsize = 25)
plt.xlabel('epoch', fontsize = 25)
plt.legend(['train', 'validation'], loc='upper left', fontsize = 25)
plt.show()

from keras.models import load_model, save_model
model.save("/content/drive/MyDrive/HeartSound/test3.1_1_1.h5")
savedModel = load_model("/content/drive/MyDrive/HeartSound/test3.1_1_1.h5")
savedModel.summary()

prediction = savedModel.predict(processed_X_val)
finalPred = [[(1 if x>0.5 else 0 ) for x in prediction[i]]for i in range(0, prediction.shape[0])]
i = 3
print(finalPred[i])
print(Y_val[i])

print(prediction[3])

layer_name = 'conv2d_2'
intermediate_layer_model = Model(inputs=model.input,
                                 outputs=model.get_layer(layer_name).output)
y_pred = intermediate_layer_model.predict(processed_X_val)

y_pred.shape

plt.imshow(y_pred[1,:,:,11:14])

from sklearn.metrics import confusion_matrix
confusion_matrix(Y_val, finalPred)
